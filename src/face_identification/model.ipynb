{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from models.resnet_v2_50 import model\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.8\n",
    "TRAINING_STEPS = 20000\n",
    "BATCH_SIZE = 28\n",
    "NUM_SAMPLES = 3\n",
    "EMBEDDINGS_DIM = 2048\n",
    "DROPOUT_KEEP_PROB = 0.8\n",
    "\n",
    "CHECKPOINT_TNTERVAL = 1000\n",
    "\n",
    "INPUT_IMG_SIZE = [224, 224]\n",
    "\n",
    "train_meta = '/home/facialrec/notebooks/datasets/VGGFace2/train_list.txt'\n",
    "train_root = '/home/facialrec/notebooks/datasets/VGGFace2/train/'\n",
    "test_meta = '/home/facialrec/notebooks/datasets/VGGFace2/test_list.txt'\n",
    "test_root = '/home/facialrec/notebooks/datasets/VGGFace2/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3141890\n",
      "169396\n"
     ]
    }
   ],
   "source": [
    "def build_dict(meta_filename, root):\n",
    "    with open(meta_filename, 'rt', encoding='utf-8') as f:\n",
    "        meta = f.read().strip().split('\\n')\n",
    "        \n",
    "    actual_files = []\n",
    "    for m in meta:\n",
    "        path = os.path.join(root, m)\n",
    "        if os.path.exists(path) and os.path.isfile(path):\n",
    "            actual_files.append(m)\n",
    "        \n",
    "    print(len(actual_files))\n",
    "    meta = [m.split('/') for m in actual_files]\n",
    "    \n",
    "    data_dict = {}\n",
    "    for id, img in meta:\n",
    "        if id in data_dict:\n",
    "            data_dict[id].append(img)\n",
    "        else:\n",
    "            data_dict[id] = [img]\n",
    "            \n",
    "    return data_dict\n",
    "\n",
    "train_dict = build_dict(train_meta, train_root)\n",
    "test_dict = build_dict(test_meta, test_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(source, num_samples):\n",
    "    assert num_samples > 0\n",
    "    source_size = len(source)\n",
    "    if num_samples < source_size:\n",
    "        indices = []\n",
    "        while len(indices) < num_samples:\n",
    "            index = np.random.randint(source_size)\n",
    "            if index not in indices:\n",
    "                indices.append(index)\n",
    "                \n",
    "        indices = np.array(indices)\n",
    "    else:\n",
    "        indices = np.random.randint(source_size, size=num_samples)\n",
    "        \n",
    "    indices = indices.astype(np.int32)\n",
    "    return [source[i] for i in indices]\n",
    "\n",
    "def load_image(key, img_id):\n",
    "    path = f'/home/facialrec/notebooks/datasets/VGGFace2/train/{key}/{img_id}'\n",
    "#     print(path)\n",
    "    img = cv2.imread(path)\n",
    "    assert img is not None, (path, img)\n",
    "    if img.ndim < 3:\n",
    "        img = img[..., np.newaxis]\n",
    "        img = np.tile(img, (1, 1, 3))\n",
    "    else:\n",
    "        img = img[..., ::-1]\n",
    "    img = cv2.resize(img, tuple(INPUT_IMG_SIZE))\n",
    "    return img\n",
    "\n",
    "def py_map(key):\n",
    "    key = key.decode()\n",
    "    anchors = train_dict[key]\n",
    "    samples = random_samples(anchors, 2 * NUM_SAMPLES)\n",
    "    anchor = samples[:NUM_SAMPLES]\n",
    "    anchor_imgs = [load_image(key, a) for a in anchor]\n",
    "    positive = samples[NUM_SAMPLES:]\n",
    "    positive_imgs = [load_image(key, p) for p in positive]\n",
    "    \n",
    "    negative_class = key\n",
    "    while negative_class == key:\n",
    "        negative_class = np.random.choice(list(train_dict.keys()))\n",
    "        \n",
    "    negatives = train_dict[negative_class]\n",
    "    negative = random_samples(negatives, NUM_SAMPLES)\n",
    "    negative_imgs = [load_image(negative_class, n) for n in negative]\n",
    "    return anchor_imgs, positive_imgs, negative_imgs\n",
    "\n",
    "def _map(i):\n",
    "    anchor, positive, negative = tf.py_func(py_map, [i], [tf.uint8, tf.uint8, tf.uint8])\n",
    "    anchor.set_shape((None, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    positive.set_shape((None, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    negative.set_shape((None, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    \n",
    "    return anchor, positive, negative\n",
    "\n",
    "def _batch_map(anchor, positive, negative):\n",
    "    anchor = tf.reshape(anchor, (-1, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    positive = tf.reshape(positive, (-1, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    negative = tf.reshape(negative, (-1, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    \n",
    "    return anchor, positive, negative\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, eps=1e-7):\n",
    "    with tf.name_scope('triplet_loss'):\n",
    "        pos_norm = tf.norm(anchor-positive, ord=2, axis=-1)\n",
    "        neg_norm = tf.norm(anchor-negative, ord=2, axis=-1)\n",
    "        loss = tf.maximum(tf.square(pos_norm) - tf.square(neg_norm) + eps, 0)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "def nonlinear_triplet_loss(anchor, positive, negative, eps=1e-7, beta=32):\n",
    "    with tf.name_scope('mse_triplet_loss'):\n",
    "        pos = -tf.square(anchor - positive) / beta + 1 + eps\n",
    "        neg = -(beta - tf.square(anchor - negative)) / beta + 1 + eps\n",
    "        \n",
    "        pos_log = tf.log(pos)\n",
    "        neg_log = tf.log(neg)\n",
    "        \n",
    "        loss = tf.reduce_sum(pos_log - neg_log, axis=-1)\n",
    "        return tf.reduce_mean(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    idx_phr = tf.placeholder(tf.string, shape=[None], name='idx')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(idx_phr)\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=500))\n",
    "    dataset = dataset.map(_map, 6)\n",
    "#     dataset = dataset.apply(tf.contrib.data.ignore_errors())\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(_batch_map, 2)\n",
    "\n",
    "    train_iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "    train_batch = train_iterator.get_next()\n",
    "    anchor, positive, negative = train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inputs, is_training_mode, dropout_keep_pro):\n",
    "    nnet = model(inputs, is_training_mode, dropout_keep_pro)\n",
    "    nnet = tf.reduce_mean(nnet, [1, 2], keepdims=True)\n",
    "    nnet = tf.identity(nnet, 'final_reduce_mean')\n",
    "\n",
    "    nnet = tf.squeeze(nnet, [1, 2])\n",
    "    nnet = tf.layers.dense(nnet, 2048, activation=tf.sigmoid)\n",
    "    nnet = tf.identity(nnet, 'final_dense')\n",
    "#     print(nnet)\n",
    "\n",
    "    with tf.variable_scope('visual_control'):\n",
    "        alpha = tf.layers.Dense(1, activation=tf.sigmoid)(nnet)\n",
    "        alpha = tf.reshape(alpha, (-1, NUM_SAMPLES, 1))\n",
    "        v = tf.reshape(nnet, (-1, NUM_SAMPLES, EMBEDDINGS_DIM))\n",
    "        vm = tf.reduce_sum(v * alpha, axis=1, keepdims=True) / tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
    "        vm = tf.tile(vm, [1, NUM_SAMPLES, 1])\n",
    "\n",
    "    with tf.variable_scope('content_control'):\n",
    "        conc_v = tf.concat([v, vm], axis=-1)\n",
    "        conc_v = tf.reshape(conc_v, (-1, 2 * EMBEDDINGS_DIM))\n",
    "        betta = tf.layers.Dense(1, activation=tf.sigmoid)(conc_v)\n",
    "        betta = tf.reshape(betta, (-1, NUM_SAMPLES, 1))\n",
    "\n",
    "    weights = alpha * betta\n",
    "\n",
    "    embeddings = tf.reduce_sum(v * weights, axis=1) / tf.reduce_sum(weights, axis=1)  \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('anchor'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):    \n",
    "        anchor_embeddings = get_model(anchor, True, DROPOUT_KEEP_PROB)\n",
    "        \n",
    "with tf.name_scope('positive'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
    "        positive_embeddings = get_model(positive, True, DROPOUT_KEEP_PROB)\n",
    "        \n",
    "with tf.name_scope('negative'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
    "        negative_embeddings = get_model(negative, True, DROPOUT_KEEP_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nonlinear_triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('training'):\n",
    "    optimizer = tf.train.MomentumOptimizer(LEARNING_RATE, MOMENTUM)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [8:47:49<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "saver = tf.train.Saver()\n",
    "summary_writer = tf.summary.FileWriter('logdir', sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(train_iterator.initializer, feed_dict={idx_phr: list(train_dict.keys())})\n",
    "    \n",
    "losses = []\n",
    "for i in tqdm(range(TRAINING_STEPS)):\n",
    "    _loss, _ = sess.run([loss, train_op])\n",
    "    \n",
    "    if i % CHECKPOINT_TNTERVAL == 0:\n",
    "        save_path = saver.save(sess, 'logdir/pretrained/model.ckpt', global_step=i)\n",
    "    losses.append(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e2791b0aba4eed8f69b790e893e0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1aa4fa7eb8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
