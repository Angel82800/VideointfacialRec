{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from models.resnet_v2_50 import model\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.8\n",
    "TRAINING_STEPS = 2000\n",
    "BATCH_SIZE = 8\n",
    "NUM_SAMPLES = 3\n",
    "EMBEDDINGS_DIM = 2048\n",
    "DROPOUT_KEEP_PROB = 0.8\n",
    "\n",
    "INPUT_IMG_SIZE = [224, 224]\n",
    "\n",
    "train_meta = '/home/facialrec/notebooks/datasets/VGGFace2/train_list.txt'\n",
    "train_root = '/home/facialrec/notebooks/datasets/VGGFace2/train/'\n",
    "test_meta = '/home/facialrec/notebooks/datasets/VGGFace2/test_list.txt'\n",
    "test_root = '/home/facialrec/notebooks/datasets/VGGFace2/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3141890\n",
      "169396\n"
     ]
    }
   ],
   "source": [
    "def build_dict(meta_filename, root):\n",
    "    with open(meta_filename, 'rt', encoding='utf-8') as f:\n",
    "        meta = f.read().strip().split('\\n')\n",
    "        \n",
    "    actual_files = []\n",
    "    for m in meta:\n",
    "        if os.path.exists(os.path.join(root, m)):\n",
    "            actual_files.append(m)\n",
    "        \n",
    "    print(len(actual_files))\n",
    "    meta = [m.split('/') for m in actual_files]\n",
    "    \n",
    "    data_dict = {}\n",
    "    for id, img in meta:\n",
    "        if id in data_dict:\n",
    "            data_dict[id].append(img)\n",
    "        else:\n",
    "            data_dict[id] = [img]\n",
    "            \n",
    "    return data_dict\n",
    "\n",
    "train_dict = build_dict(train_meta, train_root)\n",
    "test_dict = build_dict(test_meta, test_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {**train_dict, **test_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(source, num_samples):\n",
    "    assert num_samples > 0\n",
    "    source_size = len(source)\n",
    "    if num_samples < source_size:\n",
    "        indices = []\n",
    "        while len(indices) < num_samples:\n",
    "            index = np.random.randint(source_size)\n",
    "            if index not in indices:\n",
    "                indices.append(index)\n",
    "                \n",
    "        indices = np.array(indices)\n",
    "    else:\n",
    "        indices = np.random.randint(source_size, size=num_samples)\n",
    "        \n",
    "    indices = indices.astype(np.int32)\n",
    "    return [source[i] for i in indices]\n",
    "\n",
    "def load_image(key, img_id):\n",
    "    path = f'/home/facialrec/notebooks/datasets/VGGFace2/train/{key}/{img_id}'\n",
    "#     print(path)\n",
    "    img = cv2.imread(path)\n",
    "    if img.ndim < 3:\n",
    "        img = img[..., np.newaxis]\n",
    "        img = np.tile(img, (1, 1, 3))\n",
    "    else:\n",
    "        img = img[..., ::-1]\n",
    "    img = cv2.resize(img, tuple(INPUT_IMG_SIZE))\n",
    "    return img\n",
    "\n",
    "def py_map(key):\n",
    "    key = key.decode()\n",
    "    anchors = data_dict[key]\n",
    "    samples = random_samples(anchors, 2 * NUM_SAMPLES)\n",
    "    anchor = samples[:NUM_SAMPLES]\n",
    "    anchor_imgs = [load_image(key, a) for a in anchor]\n",
    "    positive = samples[NUM_SAMPLES:]\n",
    "    positive_imgs = [load_image(key, p) for p in positive]\n",
    "    \n",
    "    negative_class = key\n",
    "    while negative_class == key:\n",
    "        negative_class = np.random.choice(list(data_dict.keys()))\n",
    "        \n",
    "    negatives = data_dict[negative_class]\n",
    "    negative = random_samples(negatives, NUM_SAMPLES)\n",
    "    negative_imgs = [load_image(negative_class, n) for n in negative]\n",
    "    return anchor_imgs, positive_imgs, negative_imgs\n",
    "\n",
    "def _map(i):\n",
    "    anchor, positive, negative = tf.py_func(py_map, [i], [tf.uint8, tf.uint8, tf.uint8])\n",
    "    anchor.set_shape((None, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    positive.set_shape((None, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    negative.set_shape((None, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    \n",
    "    return anchor, positive, negative\n",
    "\n",
    "def _batch_map(anchor, positive, negative):\n",
    "    anchor = tf.reshape(anchor, (-1, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    positive = tf.reshape(positive, (-1, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    negative = tf.reshape(negative, (-1, INPUT_IMG_SIZE[0], INPUT_IMG_SIZE[1], 3))\n",
    "    \n",
    "    return anchor, positive, negative\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, eps=1e-7):\n",
    "    with tf.name_scope('triplet_loss'):\n",
    "        pos_norm = tf.norm(anchor-positive, ord=2, axis=-1)\n",
    "        neg_norm = tf.norm(anchor-negative, ord=2, axis=-1)\n",
    "        loss = tf.maximum(tf.square(pos_norm) - tf.square(neg_norm) + eps, 0)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "def nonlinear_triplet_loss(anchor, positive, negative, eps=1e-7, beta=32):\n",
    "    with tf.name_scope('mse_triplet_loss'):\n",
    "        pos = -tf.square(anchor - positive) / beta + 1 + eps\n",
    "        neg = -(beta - tf.square(anchor - negative)) / beta + 1 + eps\n",
    "        \n",
    "        pos_log = tf.log(pos)\n",
    "        neg_log = tf.log(neg)\n",
    "        \n",
    "        loss = tf.reduce_sum(pos_log - neg_log, axis=-1)\n",
    "        return tf.reduce_mean(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    idx_phr = tf.placeholder(tf.string, shape=[None], name='idx')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(idx_phr)\n",
    "    dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=500))\n",
    "    dataset = dataset.map(_map, 6)\n",
    "    dataset = dataset.apply(tf.contrib.data.ignore_errors())\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(_batch_map, 2)\n",
    "\n",
    "    train_iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "    train_batch = train_iterator.get_next()\n",
    "    anchor, positive, negative = train_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inputs, is_training_mode, dropout_keep_pro):\n",
    "    nnet = model(inputs, is_training_mode, dropout_keep_pro)\n",
    "    nnet = tf.reduce_mean(nnet, [1, 2], keepdims=True)\n",
    "    nnet = tf.identity(nnet, 'final_reduce_mean')\n",
    "\n",
    "    nnet = tf.squeeze(nnet, [1, 2])\n",
    "    nnet = tf.layers.dense(nnet, 2048, activation=tf.sigmoid)\n",
    "    nnet = tf.identity(nnet, 'final_dense')\n",
    "\n",
    "    with tf.variable_scope('visual_control'):\n",
    "        alpha = tf.layers.Dense(1, activation=tf.sigmoid)(nnet)\n",
    "        alpha = tf.reshape(alpha, (-1, NUM_SAMPLES, 1))\n",
    "        v = tf.reshape(nnet, (-1, NUM_SAMPLES, EMBEDDINGS_DIM))\n",
    "        vm = tf.reduce_sum(v * alpha, axis=1, keepdims=True) / tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
    "        vm = tf.tile(vm, [1, NUM_SAMPLES, 1])\n",
    "\n",
    "    with tf.variable_scope('content_control'):\n",
    "        conc_v = tf.concat([v, vm], axis=-1)\n",
    "        conc_v = tf.reshape(conc_v, (-1, 2 * EMBEDDINGS_DIM))\n",
    "        betta = tf.layers.Dense(1, activation=tf.sigmoid)(conc_v)\n",
    "        betta = tf.reshape(betta, (-1, NUM_SAMPLES, 1))\n",
    "\n",
    "    weights = alpha * betta\n",
    "\n",
    "    embeddings = tf.reduce_sum(v * weights, axis=1) / tf.reduce_sum(weights, axis=1)  \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('anchor'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):    \n",
    "        anchor_embeddings = model(anchor, True, DROPOUT_KEEP_PROB)\n",
    "        \n",
    "with tf.name_scope('positive'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
    "        positive_embeddings = model(positive, True, DROPOUT_KEEP_PROB)\n",
    "        \n",
    "with tf.name_scope('negative'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
    "        negative_embeddings = model(negative, True, DROPOUT_KEEP_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nonlinear_triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('training'):\n",
    "    optimizer = tf.train.MomentumOptimizer(LEARNING_RATE, MOMENTUM)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2000 [00:04<2:34:31,  4.64s/it]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "AttributeError: 'NoneType' object has no attribute 'ndim'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 158, in __call__\n    ret = func(*args)\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 45, in py_map\n    negative_imgs = [load_image(negative_class, n) for n in negative]\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 45, in <listcomp>\n    negative_imgs = [load_image(negative_class, n) for n in negative]\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 22, in load_image\n    if img.ndim < 3:\n\nAttributeError: 'NoneType' object has no attribute 'ndim'\n\n\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_UINT8, DT_UINT8, DT_UINT8], token=\"pyfunc_0\", _device=\"/device:CPU:0\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,3], [?,224,224,3], [?,224,224,3]], output_types=[DT_UINT8, DT_UINT8, DT_UINT8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_173_IteratorGetNext\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: AttributeError: 'NoneType' object has no attribute 'ndim'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 158, in __call__\n    ret = func(*args)\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 45, in py_map\n    negative_imgs = [load_image(negative_class, n) for n in negative]\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 45, in <listcomp>\n    negative_imgs = [load_image(negative_class, n) for n in negative]\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 22, in load_image\n    if img.ndim < 3:\n\nAttributeError: 'NoneType' object has no attribute 'ndim'\n\n\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_UINT8, DT_UINT8, DT_UINT8], token=\"pyfunc_0\", _device=\"/device:CPU:0\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,3], [?,224,224,3], [?,224,224,3]], output_types=[DT_UINT8, DT_UINT8, DT_UINT8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_173_IteratorGetNext\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bb95ddc833d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINING_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m: AttributeError: 'NoneType' object has no attribute 'ndim'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 158, in __call__\n    ret = func(*args)\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 45, in py_map\n    negative_imgs = [load_image(negative_class, n) for n in negative]\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 45, in <listcomp>\n    negative_imgs = [load_image(negative_class, n) for n in negative]\n\n  File \"<ipython-input-5-a9a0bf604193>\", line 22, in load_image\n    if img.ndim < 3:\n\nAttributeError: 'NoneType' object has no attribute 'ndim'\n\n\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING], Tout=[DT_UINT8, DT_UINT8, DT_UINT8], token=\"pyfunc_0\", _device=\"/device:CPU:0\"](arg0)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,3], [?,224,224,3], [?,224,224,3]], output_types=[DT_UINT8, DT_UINT8, DT_UINT8], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]\n\t [[Node: IteratorGetNext/_1 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_173_IteratorGetNext\", tensor_type=DT_UINT8, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "summary_writer = tf.summary.FileWriter('logdir', sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "sess.run(train_iterator.initializer, feed_dict={idx_phr: list(train_dict.keys())})\n",
    "    \n",
    "losses = []\n",
    "for i in tqdm(range(TRAINING_STEPS)):\n",
    "    _loss, _ = sess.run([loss, train_op])\n",
    "    losses.append(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
