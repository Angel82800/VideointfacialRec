{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import ipympl\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "MOMENTUM = 0.8\n",
    "TRAINING_STEPS = 2000\n",
    "BATCH_SIZE = 128\n",
    "NUM_SAMPLES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(np.float32)\n",
    "mean = x_train.mean()\n",
    "std = x_train.std()\n",
    "\n",
    "x_train -= mean\n",
    "x_train /= std\n",
    "\n",
    "x_train = x_train[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58348270522e40f28c58bd5b667e516a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda6d9b3198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(x_train[0, ..., 0].astype(np.float32), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "for x, y in zip(x_train, y_train):\n",
    "    if y in train_dict:\n",
    "        train_dict[y].append(x)\n",
    "    else:\n",
    "        train_dict[y] = [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(source, num_samples):\n",
    "    assert num_samples > 0\n",
    "    source_size = len(source)\n",
    "    if num_samples < source_size:\n",
    "        indices = []\n",
    "        while len(indices) < num_samples:\n",
    "            index = np.random.randint(source_size)\n",
    "            if index not in indices:\n",
    "                indices.append(index)\n",
    "                \n",
    "        indices = np.array(indices)\n",
    "    else:\n",
    "        indices = np.random.randint(source_size, size=num_samples)\n",
    "        \n",
    "    indices = indices.astype(np.int32)\n",
    "    return [source[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def py_map(i):\n",
    "    anchors = train_dict[i]\n",
    "    samples = random_samples(anchors, 2 * NUM_SAMPLES)\n",
    "    anchor = samples[:NUM_SAMPLES]\n",
    "    positive = samples[NUM_SAMPLES:]\n",
    "    \n",
    "    negative_class = i\n",
    "    while negative_class == i:\n",
    "        negative_class = np.random.randint(len(train_dict.keys()))\n",
    "        \n",
    "    negatives = train_dict[negative_class]\n",
    "    negative = random_samples(negatives, NUM_SAMPLES)\n",
    "    return anchor, positive, negative, np.int32(i), np.int32(negative_class)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def py_map(i):\n",
    "#     anchors = train_dict[i]\n",
    "#     anchor_index = np.random.randint(len(anchors))\n",
    "#     anchor = anchors[anchor_index]\n",
    "    \n",
    "#     positive_index = anchor_index\n",
    "#     while positive_index == anchor_index:\n",
    "#         positive_index = np.random.randint(len(anchors))\n",
    "#     positive = anchors[positive_index]\n",
    "    \n",
    "#     negative_class = i\n",
    "#     while negative_class == i:\n",
    "#         negative_class = np.random.randint(len(train_dict.keys()))\n",
    "\n",
    "#     negatives = train_dict[negative_class]\n",
    "#     negative = negatives[np.random.randint(len(negatives))]\n",
    "    \n",
    "#     return anchor, positive, negative, np.int32(i), np.int32(negative_class)\n",
    "\n",
    "def _map(i):\n",
    "    anchor, positive, negative, pos_class, neg_class = tf.py_func(py_map, [i], [tf.float32, tf.float32, tf.float32, tf.int32, tf.int32])\n",
    "    anchor.set_shape((None, 28, 28, 1))\n",
    "    positive.set_shape((None, 28, 28, 1))\n",
    "    negative.set_shape((None, 28, 28, 1))\n",
    "    \n",
    "    return anchor, positive, negative, pos_class, neg_class\n",
    "\n",
    "# def _map(i):\n",
    "#     anchor, positive, negative, pos_class, neg_class = tf.py_func(py_map, [i], [tf.float32, tf.float32, tf.float32, tf.int32, tf.int32])\n",
    "#     anchor.set_shape((28, 28, 1))\n",
    "#     positive.set_shape((28, 28, 1))\n",
    "#     negative.set_shape((28, 28, 1))\n",
    "    \n",
    "#     return anchor, positive, negative, pos_class, neg_class\n",
    "\n",
    "def _batch_map(anchor, positive, negative, pos_class, neg_class):\n",
    "    anchor = tf.reshape(anchor, (-1, 28, 28, 1))\n",
    "    positive = tf.reshape(positive, (-1, 28, 28, 1))\n",
    "    negative = tf.reshape(negative, (-1, 28, 28, 1))\n",
    "    \n",
    "    return anchor, positive, negative, pos_class, neg_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(inputs):\n",
    "    conv1 = tf.layers.Conv2D(32, 3, activation=tf.nn.relu, padding='same')(inputs)\n",
    "    conv2 = tf.layers.Conv2D(64, 2, activation=tf.nn.relu, padding='same')(conv1)\n",
    "    max_pool1 = tf.layers.MaxPooling2D(2, 2)(conv2)\n",
    "\n",
    "    conv3 = tf.layers.Conv2D(128, 3, activation=tf.nn.relu, padding='same')(max_pool1)\n",
    "    conv4 = tf.layers.Conv2D(256, 3, activation=tf.nn.relu, padding='same')(conv3)\n",
    "    max_pool2 = tf.layers.MaxPooling2D(2, 2)(conv4)\n",
    "\n",
    "    conv5 = tf.layers.Conv2D(256, 3, activation=tf.nn.relu, padding='same')(max_pool2)\n",
    "    conv6 = tf.layers.Conv2D(256, 3, activation=tf.nn.relu, padding='same')(conv5)\n",
    "    max_pool3 = tf.layers.MaxPooling2D(2, 2)(conv6)\n",
    "\n",
    "    flatten = tf.layers.Flatten()(max_pool3)\n",
    "    embeddings = tf.layers.Dense(32, activation=tf.sigmoid)(flatten)\n",
    "    \n",
    "    with tf.variable_scope('visual_control'):\n",
    "        alpha = tf.layers.Dense(1, activation=tf.sigmoid)(embeddings)\n",
    "        alpha = tf.reshape(alpha, (-1, NUM_SAMPLES, 1))\n",
    "        v = tf.reshape(embeddings, (-1, NUM_SAMPLES, 32))\n",
    "        vm = tf.reduce_sum(v * alpha, axis=1, keepdims=True) / tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
    "        vm = tf.tile(vm, [1, NUM_SAMPLES, 1])\n",
    "        \n",
    "    with tf.variable_scope('content_control'):\n",
    "        conc_v = tf.concat([v, vm], axis=-1)\n",
    "        conc_v = tf.reshape(conc_v, (-1, 2 * 32))\n",
    "        betta = tf.layers.Dense(1, activation=tf.sigmoid)(conc_v)\n",
    "        betta = tf.reshape(betta, (-1, NUM_SAMPLES, 1))\n",
    "        \n",
    "    weights = alpha * betta\n",
    "    \n",
    "    embeddings = tf.reduce_sum(v * weights, axis=1) / tf.reduce_sum(weights, axis=1)\n",
    "    return embeddings\n",
    "#     normalized_embeddings = embeddings / tf.norm(embeddings, ord=2, axis=-1, keepdims=True)\n",
    "#     return normalized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, eps=1e-7):\n",
    "    with tf.name_scope('triplet_loss'):\n",
    "        pos_norm = tf.norm(anchor-positive, ord=2, axis=-1)\n",
    "        neg_norm = tf.norm(anchor-negative, ord=2, axis=-1)\n",
    "        loss = tf.maximum(tf.square(pos_norm) - tf.square(neg_norm) + eps, 0)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "def nonlinear_triplet_loss(anchor, positive, negative, eps=1e-7, beta=32):\n",
    "    with tf.name_scope('mse_triplet_loss'):\n",
    "        pos = -tf.square(anchor - positive) / beta + 1 + eps\n",
    "        neg = -(beta - tf.square(anchor - negative)) / beta + 1 + eps\n",
    "        \n",
    "        pos_log = tf.log(pos)\n",
    "        neg_log = tf.log(neg)\n",
    "        \n",
    "        loss = tf.reduce_sum(pos_log - neg_log, axis=-1)\n",
    "        return tf.reduce_mean(loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(len(train_dict.keys()))\n",
    "dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size=500))\n",
    "dataset = dataset.map(_map, 6)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.map(_batch_map, 2)\n",
    "\n",
    "train_iterator = dataset.make_one_shot_iterator()\n",
    "batch = train_iterator.get_next()\n",
    "\n",
    "anchor = batch[0]\n",
    "positive = batch[1]\n",
    "negative = batch[2]\n",
    "pos_classes = batch[3]\n",
    "neg_classes = batch[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('anchor'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):    \n",
    "        anchor_embeddings = model(anchor)\n",
    "        \n",
    "with tf.name_scope('positive'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
    "        positive_embeddings = model(positive)\n",
    "        \n",
    "with tf.name_scope('negative'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE): \n",
    "        negative_embeddings = model(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('test'):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):   \n",
    "        features = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "        embeddings = model(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nonlinear_triplet_loss(anchor_embeddings, positive_embeddings, negative_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('training'):\n",
    "    optimizer = tf.train.MomentumOptimizer(LEARNING_RATE, MOMENTUM)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [05:18<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "summary_writer = tf.summary.FileWriter('logdir', sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "losses = []\n",
    "for i in tqdm(range(TRAINING_STEPS)):\n",
    "    _loss, _ = sess.run([loss, train_op])\n",
    "    losses.append(_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b7ff0cb56f46ee97627615eef13a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fda54335630>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.astype(np.float32)\n",
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[..., np.newaxis].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {}\n",
    "for x, y in zip(x_test, y_test):\n",
    "    if y in test_dict:\n",
    "        test_dict[y].append(x)\n",
    "    else:\n",
    "        test_dict[y] = [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "test_labels = []\n",
    "for key, val in test_dict.items():\n",
    "    for i in range(0, len(val)-NUM_SAMPLES+1, NUM_SAMPLES):\n",
    "        test_data.append(val[i:i+NUM_SAMPLES])\n",
    "        test_labels.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.array(test_data).reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings = sess.run(embeddings, feed_dict={features: test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings = _embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(_embeddings)\n",
    "new_embeddings = pca.transform(_embeddings) \n",
    "# new_embeddings = _embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = np.random.randint(0, len(test_labels), 500, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.array(test_labels)[sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b212dc8523d54553aecc5e12a269dff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fda5459b860>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(10):\n",
    "    indices = np.argwhere(np.array(test_labels) == i)[:, 0]\n",
    "    ax.scatter(new_embeddings[sample_indices][indices, 0], \n",
    "               new_embeddings[sample_indices][indices, 1], \n",
    "               new_embeddings[sample_indices][indices, 2], \n",
    "               label=i)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x_test = x_test[np.newaxis, ...]\n",
    "_x_test = np.transpose(_x_test, (1, 0, 2, 3, 4))\n",
    "_x_test = np.tile(_x_test, (1, NUM_SAMPLES, 1, 1, 1))\n",
    "_x_test = np.reshape(_x_test, (-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings = sess.run(embeddings, feed_dict={features: _x_test})\n",
    "_embeddings = _embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(_embeddings)\n",
    "new_embeddings = pca.transform(_embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33415e2ce17d4cf590d9945c98f7d14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd3e41a5fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices = np.random.randint(0, len(y_test), 1000, dtype=np.int32)\n",
    "_y_test = y_test[sample_indices]\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(10):\n",
    "    indices = np.argwhere(np.array(_y_test) == i)[:, 0]\n",
    "    ax.scatter(new_embeddings[sample_indices][indices, 0], \n",
    "               new_embeddings[sample_indices][indices, 1], \n",
    "               new_embeddings[sample_indices][indices, 2], \n",
    "               label=i)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
