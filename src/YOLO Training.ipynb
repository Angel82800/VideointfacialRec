{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# YOLO-based face detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='resnet_v2_50'\n",
    "\n",
    "TRAINING_STEPS = 300000\n",
    "STEPS_PER_SUMMARY = 500\n",
    "\n",
    "DATASET_N_WORKERS=32\n",
    "BATCH_SIZE=48\n",
    "BUFFER_SIZE=BATCH_SIZE*10\n",
    "INPUT_IMAGE_SIZE=[416, 416]\n",
    "OUTPUT_GRIDS=[\n",
    "    [52, 52],\n",
    "    [26, 26],\n",
    "    [13, 13]\n",
    "]\n",
    "EXCLUDE_CLASSES=True\n",
    "N_AUGMENTED = 9\n",
    "\n",
    "CONFIDENCE_TRESH = 0.5\n",
    "IOU_TRESH = 0.6\n",
    "\n",
    "DROPOUT_KEEP_PROB = 0.5\n",
    "LEARNING_RATE = 1e-4\n",
    "LEARNING_RATE_DECAY = 0.99\n",
    "LEARNING_RATE_DECAY_STEPS = 2000\n",
    "GRAD_CLIP_VALUE = 20\n",
    "\n",
    "STEPS_PER_CHECKPOINT = 2500\n",
    "GPU_MEMORY_FRACTION = 0.8\n",
    "\n",
    "SUMMARIZE_GRADIENTS = True\n",
    "\n",
    "TRAINING_DIR = './training'\n",
    "ALLOW_RESTORING = True\n",
    "\n",
    "ENABLED_GPUS = [0]\n",
    "\n",
    "DATASETS_PATH = '/home/facialrec/notebooks/VideointfacialRec/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import imgaug\n",
    "import importlib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "from imageio import imread\n",
    "from detector.utils.data import smart_resize, convert_sample_to_YOLO_preresized, convert_YOLO_result_to_normal, non_max_suppression, smart_resize\n",
    "from detector.utils.plot import plot_confusion_matrix\n",
    "\n",
    "_model_py_module = importlib.import_module('detector.models.%s' % MODEL)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DIR = os.path.join(TRAINING_DIR, MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training samples:   12880\n",
      "The number of validation samples: 3226\n",
      "The number of classes:            0\n"
     ]
    }
   ],
   "source": [
    "import detector.datasets\n",
    "from detector.datasets import REGISTERED_CLASSES, reset_classes, get_class_id\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "DATASETS = [\n",
    "#     detector.datasets.FaceScrub_get_loader(os.path.join(DATASETS_PATH, 'faceScrub')),\n",
    "    detector.datasets.WIDER_get_loader(os.path.join(DATASETS_PATH, 'WIDER')),\n",
    "]\n",
    "\n",
    "reset_classes()\n",
    "\n",
    "DATASET_GETTERS = {i: d('annotation_getter') for i, d in enumerate(DATASETS)}\n",
    "for item in DATASETS:\n",
    "    item('info')\n",
    "N_CLASSES = len(REGISTERED_CLASSES)\n",
    "if EXCLUDE_CLASSES:\n",
    "    N_CLASSES = 0\n",
    "\n",
    "TRAIN_SAMPLES = [(i, entry) for i, d in enumerate(DATASETS) for entry in d('training')]\n",
    "VALID_SAMPLES = [(i, entry) for i, d in enumerate(DATASETS) for entry in d('valid')]\n",
    "\n",
    "print('The number of training samples:  ', len(TRAIN_SAMPLES))\n",
    "print('The number of validation samples:', len(VALID_SAMPLES))\n",
    "print('The number of classes:           ', N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dataset'):\n",
    "    _seq = imgaug.augmenters.Sequential([\n",
    "        imgaug.augmenters.Fliplr(0.5),\n",
    "        imgaug.augmenters.Sometimes(0.5,\n",
    "            imgaug.augmenters.Affine(\n",
    "                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "                rotate=(-5, 5),\n",
    "                shear=(-8, 8),\n",
    "                order=[0, 1],\n",
    "                cval=(0, 255),\n",
    "                mode=imgaug.ALL\n",
    "            )\n",
    "        ),\n",
    "        imgaug.augmenters.SomeOf((0, 3),\n",
    "            [\n",
    "                imgaug.augmenters.OneOf([\n",
    "                    imgaug.augmenters.GaussianBlur((0, 1.0)),\n",
    "                    imgaug.augmenters.AverageBlur(k=(2, 5)),\n",
    "                    imgaug.augmenters.MedianBlur(k=(3, 7)),\n",
    "                ]),\n",
    "                imgaug.augmenters.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "                imgaug.augmenters.ContrastNormalization((0.75, 1.25)),\n",
    "                imgaug.augmenters.Multiply((0.75, 1.25), per_channel=0.2),\n",
    "                imgaug.augmenters.Add((-10, 10), per_channel=0.5)\n",
    "            ]\n",
    "        )\n",
    "    ])\n",
    "    _seq_det = _seq.to_deterministic()\n",
    "    \n",
    "    def _map_fn(entry, dataset_id):\n",
    "        try:\n",
    "            if isinstance(entry, bytes):\n",
    "                entry = entry.decode()\n",
    "        \n",
    "            image = imread(entry)\n",
    "            if image.ndim == 2:\n",
    "                image = image[..., np.newaxis]\n",
    "                image = np.tile(image, [1, 1, 3])\n",
    "            elif image.ndim == 3 and image.shape[-1] == 4:\n",
    "                image = image[..., :-1]\n",
    "            elif image.ndim != 3 or image.shape[-1] != 3:\n",
    "                return None                        \n",
    "\n",
    "            getter = DATASET_GETTERS[dataset_id]\n",
    "            result = getter(entry)\n",
    "            if result is None:\n",
    "                return None\n",
    "            \n",
    "            bboxes, classes = result\n",
    "            if classes is None or EXCLUDE_CLASSES:\n",
    "                has_classes = False\n",
    "            else:\n",
    "                has_classes = True\n",
    "                classes = [get_class_id(c) for c in classes]\n",
    "                \n",
    "            instances = [[image, has_classes, bboxes, classes]]\n",
    "            \n",
    "            bboxes_list_aug = imgaug.BoundingBoxesOnImage([imgaug.BoundingBox(x1=x, y1=y, x2=x+w, y2=y+h) for x,y,w,h in bboxes], shape=image.shape)\n",
    "            \n",
    "            images_aug = _seq_det.augment_images([image for j in range(N_AUGMENTED)])\n",
    "            bboxes_list_aug = _seq_det.augment_bounding_boxes([bboxes_list_aug for j in range(N_AUGMENTED)])\n",
    "            \n",
    "            for image_aug, bboxes_aug in zip(images_aug, bboxes_list_aug):\n",
    "                bboxes_aug = [(min(max(b.x1, 0), image_aug.shape[1]), min(max(b.y1, 0), image_aug.shape[0]),\n",
    "                               min(max(b.x2, 0), image_aug.shape[1]), min(max(b.y2, 0), image_aug.shape[0])) for b in bboxes_aug.bounding_boxes]\n",
    "                \n",
    "                bboxes_aug = [(x1,y1,x2-x1,y2-y1) for x1,y1,x2,y2 in bboxes_aug]\n",
    "                \n",
    "                instances.append([image_aug, has_classes, bboxes_aug, classes])\n",
    "            \n",
    "            samples = []\n",
    "            for instance in instances:\n",
    "                image, has_classes, bboxes, classes = instance\n",
    "                \n",
    "                result = smart_resize(image, INPUT_IMAGE_SIZE[0], INPUT_IMAGE_SIZE[1], ret_image_shifts=True)\n",
    "                image, resize_params = result\n",
    "\n",
    "                sample = [image]\n",
    "\n",
    "                if N_CLASSES > 0:\n",
    "                    sample = sample + [np.array([has_classes])]\n",
    "\n",
    "                for output_grid in OUTPUT_GRIDS:\n",
    "                    if has_classes:\n",
    "                        result = convert_sample_to_YOLO_preresized(image, resize_params, output_grid, bboxes, classes)\n",
    "                    else:\n",
    "                        result = convert_sample_to_YOLO_preresized(image, resize_params, output_grid, bboxes)\n",
    "\n",
    "                    if result is None:\n",
    "                        return None\n",
    "\n",
    "                    if has_classes:\n",
    "                        conf_probs_map, bboxes_map, classes_map = result\n",
    "                        sample = sample + [conf_probs_map, bboxes_map, classes_map]\n",
    "                    else:\n",
    "                        conf_probs_map, bboxes_map = result\n",
    "                        sample = sample + [conf_probs_map, bboxes_map]\n",
    "                        if N_CLASSES > 0:\n",
    "                            sample = sample + [np.zeros_like(conf_probs_map, dtype=np.int32)]\n",
    "                samples.append(sample)\n",
    "\n",
    "            return tuple(zip(*samples))\n",
    "            \n",
    "        except Exception as ex:\n",
    "            #print(entry, repr(ex))\n",
    "            #return None\n",
    "            raise\n",
    "\n",
    "    #            image\n",
    "    _dtypes = [tf.uint8]\n",
    "    _shapes = [INPUT_IMAGE_SIZE+[3]]\n",
    "    \n",
    "    if N_CLASSES > 0:\n",
    "        #                  has_classes\n",
    "        _dtypes = _dtypes + [tf.bool]\n",
    "        _shapes = _shapes + [[1]]\n",
    "    \n",
    "    for output_grid in OUTPUT_GRIDS:\n",
    "        #                      obj conf |  bbox \n",
    "        _dtypes = _dtypes + [tf.float32, tf.float32]\n",
    "        _shapes = _shapes + [output_grid+[1], output_grid+[4]]\n",
    "    \n",
    "        if N_CLASSES > 0:\n",
    "            #                has_classes |  classes\n",
    "            _dtypes = _dtypes + [tf.int32]\n",
    "            _shapes = _shapes + [output_grid+[1]]\n",
    "\n",
    "    dataset_samples_tf_phr = tf.placeholder(tf.string, name='samples')\n",
    "    dataset_ids_tf_phr = tf.placeholder(tf.int32, name='ids')\n",
    "\n",
    "    dataset = tf.data.Dataset().from_tensor_slices((dataset_samples_tf_phr, dataset_ids_tf_phr))\n",
    "    dataset = dataset.map(lambda entry, dataset_id: tf.py_func(_map_fn, [entry, dataset_id], _dtypes), DATASET_N_WORKERS)\n",
    "    dataset = dataset.apply(tf.contrib.data.ignore_errors())\n",
    "#     dataset = dataset.cache()\n",
    "    dataset = dataset.flat_map(lambda *samples: tf.data.Dataset.from_tensor_slices(samples))\n",
    "    dataset = dataset.map(lambda *sample: tuple(tf.reshape(item, shape) for item, shape in zip(sample, _shapes)), DATASET_N_WORKERS)\n",
    "    dataset = dataset.shuffle(buffer_size=BUFFER_SIZE)\n",
    "    dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "train_iterator = dataset.make_initializable_iterator('train')\n",
    "valid_iterator = dataset.make_initializable_iterator('valid')\n",
    "\n",
    "train_batch = train_iterator.get_next()\n",
    "valid_batch = valid_iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_channels = 1+4\n",
    "if N_CLASSES > 0:\n",
    "    if N_CLASSES == 2:\n",
    "        _out_channels += 1\n",
    "    else:\n",
    "        _out_channels += N_CLASSES\n",
    "\n",
    "_feature_embedd_channels = 256\n",
    "\n",
    "with tf.name_scope('detector'):\n",
    "    keep_prob = tf.placeholder_with_default(1., [], name='keep_prob')\n",
    "    is_training_mode = tf.placeholder_with_default(False, [], name='is_training_mode')\n",
    "    data_loader_mode = tf.placeholder_with_default('train-pipe', [], name='data_loader_mode')\n",
    "    \n",
    "    _batch = tf.case([(tf.equal(data_loader_mode, 'train-pipe'), lambda: train_batch),\n",
    "                      (tf.equal(data_loader_mode, 'valid-pipe'), lambda: valid_batch)],\n",
    "                     exclusive=True)\n",
    "    _batch = tuple(tf.reshape(_batch[i], [-1] + shape[1:].as_list()) for i, shape in enumerate(dataset.output_shapes))\n",
    "    \n",
    "    with tf.name_scope('inputs'):\n",
    "        inputs_image = tf.identity(_batch[0], name='image')\n",
    "        \n",
    "    with tf.name_scope('targets'):\n",
    "        if N_CLASSES > 0:\n",
    "            targets_has_classes = tf.identity(_batch[1], name='has_classes')\n",
    "            counter = 2\n",
    "        else:\n",
    "            counter = 1\n",
    "\n",
    "        targets_nodes = []\n",
    "        for i, grid in enumerate(OUTPUT_GRIDS):\n",
    "            with tf.name_scope('grid-%ix%i' % tuple(grid)):\n",
    "                targets_conf_probs = tf.identity(_batch[counter], name='conf_probs')\n",
    "                counter+=1\n",
    "                \n",
    "                targets_bboxes = tf.identity(_batch[counter], name='bboxes_xy')\n",
    "                counter+=1\n",
    "                \n",
    "                if N_CLASSES > 0:\n",
    "                    targets_classes = tf.identity(_batch[counter], name='classes')\n",
    "                    counter+=1\n",
    "\n",
    "                    targets_nodes.append((targets_conf_probs, targets_bboxes, targets_classes))\n",
    "                else:\n",
    "                    targets_nodes.append((targets_conf_probs, targets_bboxes))\n",
    "        \n",
    "    with tf.name_scope('model'):\n",
    "        _nodes = _model_py_module.model(tf.cast(inputs_image, tf.float32), OUTPUT_GRIDS, is_training_mode, keep_prob)\n",
    "        \n",
    "        _output_nodes = []\n",
    "        _prev_features_map = None\n",
    "        for _net, output_grid in reversed(list(zip(_nodes, OUTPUT_GRIDS))):\n",
    "            with tf.variable_scope('grid-%ix%i' % tuple(output_grid)):\n",
    "                with slim.arg_scope([slim.conv2d], padding='SAME'):\n",
    "                    _net = slim.conv2d(_net, _feature_embedd_channels, [1, 1])\n",
    "                    \n",
    "                    if _prev_features_map is not None:\n",
    "                        _net = _net + tf.image.resize_nearest_neighbor(_prev_features_map, [_prev_features_map.shape[1]*2, _prev_features_map.shape[2]*2])\n",
    "                        _net = slim.conv2d(_net, _feature_embedd_channels, [3, 3])\n",
    "                    \n",
    "                    _prev_features_map = _net\n",
    "                    \n",
    "                    _net = slim.conv2d(_net, _out_channels, [1, 1], activation_fn=None, weights_initializer=tf.zeros_initializer())\n",
    "                    \n",
    "                    _output_nodes.append(_net)\n",
    "\n",
    "                assert _net.shape[1] == output_grid[0] and _net.shape[2] == output_grid[1], \\\n",
    "                    'Incorrect ouput grid shape: must be [%d, %d], but [%d, %d] found.' % tuple(output_grid + [_net.shape[1], _net.shape[2]])\n",
    "        _output_nodes = list(reversed(_output_nodes))\n",
    "    \n",
    "    with tf.name_scope('outputs'):\n",
    "        output_nodes = []\n",
    "        for _net, grid in zip(_output_nodes, OUTPUT_GRIDS):\n",
    "            with tf.name_scope('grid-%ix%i' % tuple(grid)):\n",
    "                outputs_conf_probs_logits = _net[:, :, :, 0:1]\n",
    "                outputs_conf_probs = tf.identity(tf.nn.sigmoid(outputs_conf_probs_logits), name='conf_probs')\n",
    "\n",
    "                outputs_bboxes = _net[:, :, :, 1:5]\n",
    "                \n",
    "                outputs_bboxes_xy = tf.sigmoid(outputs_bboxes[:, :, :, :2])\n",
    "                outputs_bboxes_wh_log = outputs_bboxes[:, :, :, 2:]\n",
    "                outputs_bboxes_wh = tf.exp(outputs_bboxes_wh_log)\n",
    "                \n",
    "                outputs_bboxes = tf.identity(tf.concat([outputs_bboxes_xy, outputs_bboxes_wh], axis=-1), name='bboxes')\n",
    "\n",
    "                if N_CLASSES > 0:\n",
    "                    outputs_classes_logits = _net[:, :, :, 5:]\n",
    "                    if N_CLASSES == 1 or N_CLASSES == 2:\n",
    "                        outputs_classes_probs = tf.sigmoid(outputs_classes_logits)\n",
    "\n",
    "                        outputs_classes = tf.identity(tf.cast(outputs_classes_probs >= 0.5, tf.int32)[..., 0], name='classes')\n",
    "                    else:\n",
    "                        outputs_classes_probs = tf.nn.softmax(outputs_classes_logits, dim=-1)\n",
    "\n",
    "                        outputs_classes = tf.identity(tf.argmax(outputs_classes_probs, axis=-1), name='classes')\n",
    "\n",
    "                    output_nodes.append(((outputs_conf_probs_logits, outputs_conf_probs),\n",
    "                                         (outputs_bboxes_wh_log, outputs_bboxes),\n",
    "                                         (outputs_classes_logits, outputs_classes_probs, outputs_classes)))\n",
    "                else:\n",
    "                    output_nodes.append(((outputs_conf_probs_logits, outputs_conf_probs),\n",
    "                                         (outputs_bboxes_wh_log, outputs_bboxes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting model's pretrained weights [OK]\n"
     ]
    }
   ],
   "source": [
    "print('Getting model\\'s pretrained weights ', flush=True, end='')\n",
    "try:\n",
    "    _model_py_module.get_weights()\n",
    "    model_initial_weights_loader = _model_py_module.get_restore_op()\n",
    "    print('[OK]', flush=True)\n",
    "except Exception as ex:\n",
    "    model_initial_weights_loader = None\n",
    "    print('[Failed]', flush=True)\n",
    "    print(repr(ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scope = tf.name_scope('training')\n",
    "with training_scope:\n",
    "    with tf.name_scope('losses'):\n",
    "        for output_grid, _targets_nodes, _outputs_nodes in zip(OUTPUT_GRIDS, targets_nodes, output_nodes):\n",
    "            with tf.name_scope('grid-%ix%i' % tuple(output_grid)):\n",
    "                if N_CLASSES > 0:\n",
    "                    targets_conf_probs, targets_bboxes, targets_classes = _targets_nodes\n",
    "                    \n",
    "                    ((outputs_conf_probs_logits, outputs_conf_probs),\n",
    "                     (outputs_bboxes_wh_log, outputs_bboxes),\n",
    "                     (outputs_classes_logits, outputs_classes_probs, outputs_classes)) = _outputs_nodes\n",
    "                    \n",
    "                    _targets_classes = tf.cast(targets_classes, tf.int32)\n",
    "                    \n",
    "                    _targets_classes = _targets_classes[..., 0]\n",
    "                    _targets_classes_one_hot = tf.one_hot(_targets_classes, N_CLASSES)\n",
    "                    if N_CLASSES == 2:\n",
    "                        _targets_classes_probs = tf.cast(tf.expand_dims(_targets_classes, axis=-1), tf.float32)\n",
    "                    else:\n",
    "                        _targets_classes_probs = tf.cast(_targets_classes_one_hot, tf.float32)\n",
    "                else:\n",
    "                    targets_conf_probs, targets_bboxes = _targets_nodes\n",
    "                    ((outputs_conf_probs_logits, outputs_conf_probs),\n",
    "                     (outputs_bboxes_wh_log, outputs_bboxes)) = _outputs_nodes\n",
    "                    \n",
    "                _targets_conf_probs = tf.cast(targets_conf_probs, tf.float32)\n",
    "                _targets_bboxes = tf.cast(targets_bboxes, tf.float32)\n",
    "                _targets_bboxes_xy = _targets_bboxes[..., :2]\n",
    "                _targets_bboxes_wh = _targets_bboxes[..., 2:]\n",
    "                    \n",
    "                _targets_conf_probs_bin = tf.cast(_targets_conf_probs >= CONFIDENCE_TRESH, tf.float32)\n",
    "                _outputs_conf_probs_bin = tf.cast(outputs_conf_probs >= CONFIDENCE_TRESH, tf.float32)\n",
    "                        \n",
    "                _detectors_mask = tf.equal(tf.minimum(_targets_conf_probs_bin, _outputs_conf_probs_bin), 1)\n",
    "                _detectors_mask = _detectors_mask[..., 0]\n",
    "\n",
    "                _targets_bboxes_xy_actual = tf.boolean_mask(_targets_bboxes_xy, _detectors_mask)\n",
    "                _targets_bboxes_wh_actual = tf.boolean_mask(_targets_bboxes_wh, _detectors_mask)\n",
    "\n",
    "                _outputs_bboxes_xy_actual = tf.boolean_mask(outputs_bboxes[..., :2], _detectors_mask)\n",
    "                _outputs_bboxes_wh_log_actual = tf.boolean_mask(outputs_bboxes_wh_log, _detectors_mask)\n",
    "\n",
    "                # conf_probs_loss\n",
    "\n",
    "                _n_objects = tf.reduce_mean(tf.reduce_sum(_targets_conf_probs_bin, axis=[1, 2, 3]))\n",
    "                _n_no_objects = tf.reduce_mean(tf.reduce_sum(1-_targets_conf_probs_bin, axis=[1, 2, 3]))\n",
    "\n",
    "                _n_median_class = tf.contrib.distributions.percentile([_n_no_objects, _n_objects], 50)\n",
    "                _n_max_class = tf.reduce_max([_n_objects, _n_no_objects])\n",
    "\n",
    "                _object_scale = (_n_max_class / _n_objects)\n",
    "                _no_object_scale = (_n_max_class / _n_no_objects)\n",
    "\n",
    "                _no_objects_loss = -(1 - _targets_conf_probs) * tf.log(tf.maximum(1-outputs_conf_probs, 1e-6))\n",
    "                _no_objects_loss = tf.reduce_sum(_no_objects_loss, axis=[1, 2, 3])\n",
    "\n",
    "                _objects_loss = -_targets_conf_probs * tf.log(tf.maximum(outputs_conf_probs, 1e-6))\n",
    "                _objects_loss = tf.reduce_sum(_objects_loss, axis=[1, 2, 3])\n",
    "\n",
    "                conf_probs_loss = (_object_scale * _objects_loss + _no_object_scale * _no_objects_loss) / np.mean(output_grid)\n",
    "                conf_probs_loss = tf.reduce_mean(conf_probs_loss)\n",
    "\n",
    "                tf.losses.add_loss(tf.cond(tf.is_finite(conf_probs_loss), lambda: conf_probs_loss, lambda: tf.constant(0, tf.float32)))\n",
    "\n",
    "                # coordinates_loss\n",
    "\n",
    "                _coordinates_scale = 5\n",
    "\n",
    "                xy_loss = _coordinates_scale * tf.losses.mean_squared_error(_targets_bboxes_xy_actual, _outputs_bboxes_xy_actual, loss_collection=None)\n",
    "                tf.losses.add_loss(tf.cond(tf.is_finite(xy_loss), lambda: xy_loss, lambda: tf.constant(0, tf.float32)))\n",
    "\n",
    "                wh_loss = _coordinates_scale * tf.losses.mean_squared_error(tf.log(_targets_bboxes_wh_actual), _outputs_bboxes_wh_log_actual, loss_collection=None)\n",
    "                tf.losses.add_loss(tf.cond(tf.is_finite(wh_loss), lambda: wh_loss, lambda: tf.constant(0, tf.float32)))\n",
    "\n",
    "                # classes_loss\n",
    "\n",
    "                if N_CLASSES > 0:                    \n",
    "                    _detectors_mask_actual = tf.boolean_mask(_detectors_mask, targets_has_classes[:, 0])\n",
    "                    _targets_classes_probs_actual = tf.boolean_mask(_targets_classes_probs, targets_has_classes[:, 0])\n",
    "                    outputs_classes_probs_actual = tf.boolean_mask(outputs_classes_probs, targets_has_classes[:, 0])\n",
    "                    \n",
    "                    _targets_classes_probs_actual = tf.boolean_mask(_targets_classes_probs, _detectors_mask_actual)\n",
    "                    outputs_classes_probs_actual = tf.boolean_mask(outputs_classes_probs, _detectors_mask_actual)\n",
    "\n",
    "                    _n_classes = tf.reduce_sum(tf.boolean_mask(_targets_classes_one_hot, _detectors_mask_actual), axis=0, keepdims=True)\n",
    "                    _n_median_class = tf.contrib.distributions.percentile(_n_classes, 50, axis=[-1], keep_dims=True)\n",
    "\n",
    "                    _classes_scale = (_n_median_class / tf.maximum(_n_classes, 1e-6))\n",
    "\n",
    "                    if N_CLASSES == 2: # bce\n",
    "                        classes_loss = -(_classes_scale[..., 1:] * _targets_classes_probs_actual * tf.log(tf.maximum(outputs_classes_probs_actual, 1e-6)) +\n",
    "                                         _classes_scale[..., 0:1] * (1-_targets_classes_probs_actual) * tf.log(tf.maximum(1-outputs_classes_probs_actual, 1e-6)))\n",
    "                    else: # cce\n",
    "                        classes_loss = -tf.reduce_sum(_classes_scale * _targets_classes_probs_actual * tf.log(tf.maximum(outputs_classes_probs_actual, 1e-6)), axis=-1)\n",
    "\n",
    "                    classes_loss = tf.reduce_mean(classes_loss)\n",
    "\n",
    "                    tf.losses.add_loss(tf.cond(tf.is_finite(classes_loss), lambda: classes_loss, lambda: tf.constant(0, tf.float32)))\n",
    "\n",
    "        loss = tf.losses.get_total_loss(False)\n",
    "        _train_loss = tf.losses.get_total_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a training operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Var resnet_v2_50/block3/unit_6/bottleneck_v2/conv3/biases has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/preact/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/preact/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/shortcut/biases has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/conv1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/conv2/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_1/bottleneck_v2/conv3/biases has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/preact/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/preact/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/conv1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/conv2/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_2/bottleneck_v2/conv3/biases has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/preact/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/preact/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/conv1/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/conv2/BatchNorm/beta has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/block4/unit_3/bottleneck_v2/conv3/biases has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/postnorm/gamma has no gradient\n",
      "INFO:tensorflow:Var resnet_v2_50/postnorm/beta has no gradient\n"
     ]
    }
   ],
   "source": [
    "with training_scope:\n",
    "    step_var = tf.Variable(0, trainable=False)\n",
    "    step_inc_op = step_var.assign(step_var + 1)\n",
    "  \n",
    "    _params = tf.trainable_variables()\n",
    "    \n",
    "    _excludes = _model_py_module.exclude_params()\n",
    "    if _excludes:\n",
    "        _params = list(filter(lambda x: any([item not in x.name for item in _excludes]), _params))\n",
    "\n",
    "    with tf.name_scope('optimizer'):\n",
    "        with tf.name_scope('params'):\n",
    "            lr_var = tf.Variable(LEARNING_RATE, trainable=False)\n",
    "            \n",
    "            if LEARNING_RATE_DECAY and LEARNING_RATE_DECAY_STEPS:\n",
    "                lr_var = tf.train.exponential_decay(lr_var, step_var, LEARNING_RATE_DECAY_STEPS, LEARNING_RATE_DECAY, staircase=False)\n",
    "\n",
    "        _update_ops = tf.get_collection(slim.ops.GraphKeys.UPDATE_OPS)\n",
    "        _optimizer = tf.train.AdamOptimizer(lr_var)\n",
    "        train_op = slim.learning.create_train_op(_train_loss, _optimizer,\n",
    "                                                 clip_gradient_norm=(GRAD_CLIP_VALUE if GRAD_CLIP_VALUE is not None else 0),\n",
    "                                                 update_ops=_update_ops,\n",
    "                                                 variables_to_train=_params,\n",
    "                                                 summarize_gradients=SUMMARIZE_GRADIENTS)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with training_scope:\n",
    "    with tf.name_scope('metrics'):\n",
    "        conf_probs_accuracy = []\n",
    "        conf_probs_precision = []\n",
    "        conf_probs_recall = []\n",
    "        conf_probs_f1_score = []\n",
    "        \n",
    "        bboxes_IoU = []\n",
    "        \n",
    "        if N_CLASSES > 0:\n",
    "            classes_accuracy = []\n",
    "\n",
    "            classes_confusion_matrix = []\n",
    "            \n",
    "            classes_confusion_matrix_img = []\n",
    "\n",
    "        for output_grid, _targets_nodes, _outputs_nodes in zip(OUTPUT_GRIDS, targets_nodes, output_nodes):\n",
    "            with tf.name_scope('grid-%ix%i' % tuple(output_grid)):\n",
    "                if N_CLASSES > 0:\n",
    "                    targets_conf_probs, targets_bboxes, targets_classes = _targets_nodes\n",
    "                    \n",
    "                    ((outputs_conf_probs_logits, outputs_conf_probs),\n",
    "                     (outputs_bboxes_wh_log, outputs_bboxes),\n",
    "                     (outputs_classes_logits, outputs_classes_probs, outputs_classes)) = _outputs_nodes\n",
    "                    \n",
    "                    _targets_classes = tf.cast(targets_classes, tf.int32)\n",
    "                    \n",
    "                    _targets_classes = _targets_classes[..., 0]\n",
    "                    _targets_classes_one_hot = tf.one_hot(_targets_classes, N_CLASSES)\n",
    "                    if N_CLASSES == 2:\n",
    "                        _targets_classes_probs = tf.cast(tf.expand_dims(_targets_classes, axis=-1), tf.float32)\n",
    "                    else:\n",
    "                        _targets_classes_probs = tf.cast(_targets_classes_one_hot, tf.float32)\n",
    "                else:\n",
    "                    targets_conf_probs, targets_bboxes = _targets_nodes\n",
    "                    ((outputs_conf_probs_logits, outputs_conf_probs),\n",
    "                     (outputs_bboxes_wh_log, outputs_bboxes)) = _outputs_nodes\n",
    "                    \n",
    "                _targets_conf_probs = tf.cast(targets_conf_probs, tf.float32)\n",
    "                _targets_bboxes = tf.cast(targets_bboxes, tf.float32)\n",
    "                _targets_bboxes_xy = _targets_bboxes[..., :2]\n",
    "                _targets_bboxes_wh = _targets_bboxes[..., 2:]\n",
    "                    \n",
    "                _targets_conf_probs_bin = tf.cast(_targets_conf_probs >= CONFIDENCE_TRESH, tf.float32)\n",
    "                _outputs_conf_probs_bin = tf.cast(outputs_conf_probs >= CONFIDENCE_TRESH, tf.float32)\n",
    "                        \n",
    "                _detectors_mask = tf.equal(tf.minimum(_targets_conf_probs_bin, _outputs_conf_probs_bin), 1)\n",
    "                _detectors_mask = _detectors_mask[..., 0]\n",
    "\n",
    "                _targets_bboxes_xy_actual = tf.boolean_mask(_targets_bboxes_xy, _detectors_mask)\n",
    "                _targets_bboxes_wh_actual = tf.boolean_mask(_targets_bboxes_wh, _detectors_mask)\n",
    "\n",
    "                _outputs_bboxes_xy_actual = tf.boolean_mask(outputs_bboxes[..., :2], _detectors_mask)\n",
    "                _outputs_bboxes_wh_log_actual = tf.boolean_mask(outputs_bboxes_wh_log, _detectors_mask)\n",
    "                _outputs_bboxes_wh_actual = tf.boolean_mask(outputs_bboxes[..., 2:], _detectors_mask)\n",
    "                \n",
    "                # Confidence accuracy\n",
    "\n",
    "                _targets_conf_probs_bin_flatten = tf.reshape(_targets_conf_probs_bin, [-1])\n",
    "                outputs_conf_probs_bin_flatten = tf.reshape(_outputs_conf_probs_bin, [-1])\n",
    "\n",
    "                _true_positives = tf.reduce_sum(tf.minimum(_targets_conf_probs_bin_flatten, outputs_conf_probs_bin_flatten))\n",
    "                _true_negatives = tf.reduce_sum(tf.minimum(1-_targets_conf_probs_bin_flatten, 1-outputs_conf_probs_bin_flatten))\n",
    "                _false_positives = tf.reduce_sum(tf.minimum(1-_targets_conf_probs_bin_flatten, outputs_conf_probs_bin_flatten))\n",
    "                _false_negatives = tf.reduce_sum(tf.minimum(_targets_conf_probs_bin_flatten, 1-outputs_conf_probs_bin_flatten))\n",
    "\n",
    "                conf_probs_accuracy.append(tf.reduce_mean((_true_positives+_true_negatives)/tf.maximum(_true_positives+_false_positives+_false_negatives+_true_negatives, 1e-9)))\n",
    "                conf_probs_precision.append(tf.reduce_mean(_true_positives/tf.maximum(_true_positives+_false_positives, 1e-9)))\n",
    "                conf_probs_recall.append(tf.reduce_mean(_true_positives/tf.maximum(_true_positives+_false_negatives, 1e-9)))\n",
    "                conf_probs_f1_score.append(2*(conf_probs_precision[-1] * conf_probs_recall[-1]) / tf.maximum(conf_probs_precision[-1] + conf_probs_recall[-1], 1e-9))\n",
    "\n",
    "                # IoU\n",
    "\n",
    "                # intersection-over-union\n",
    "\n",
    "                # correction of negative values of bboxes\n",
    "\n",
    "                _targets_bboxes_xy_actual_corrected = tf.maximum(_targets_bboxes_xy_actual, 0)\n",
    "                _targets_bboxes_wh_actual_corrected = tf.maximum(_targets_bboxes_wh_actual, 0)\n",
    "                _outputs_bboxes_xy_actual_corrected = tf.maximum(_outputs_bboxes_xy_actual, 0)\n",
    "                _outputs_bboxes_wh_actual_corrected = tf.maximum(_outputs_bboxes_wh_actual, 0)\n",
    "\n",
    "                _targets_bboxes_wh_actual_half = _targets_bboxes_wh_actual_corrected / 2.\n",
    "                _targets_mins  = _targets_bboxes_xy_actual_corrected - _targets_bboxes_wh_actual_half\n",
    "                _targets_maxes = _targets_bboxes_xy_actual_corrected + _targets_bboxes_wh_actual_half\n",
    "\n",
    "                _outputs_bboxes_wh_actual_half = _outputs_bboxes_wh_actual_corrected / 2.\n",
    "                _outputs_mins  = _outputs_bboxes_xy_actual_corrected - _outputs_bboxes_wh_actual_half\n",
    "                _outputs_maxes = _outputs_bboxes_xy_actual_corrected + _outputs_bboxes_wh_actual_half       \n",
    "\n",
    "                _intersect_mins = tf.maximum(_targets_mins, _outputs_mins)\n",
    "                _intersect_maxes = tf.minimum(_targets_maxes, _outputs_maxes)\n",
    "                _intersect_wh = tf.maximum(0., _intersect_maxes - _intersect_mins)\n",
    "\n",
    "                _intersect_areas = _intersect_wh[..., 0] * _intersect_wh[..., 1]\n",
    "\n",
    "                _targets_areas = _targets_bboxes_wh_actual_corrected[..., 0] * _targets_bboxes_wh_actual_corrected[..., 1]\n",
    "                _outputs_areas = _outputs_bboxes_wh_actual_corrected[..., 0] * _outputs_bboxes_wh_actual_corrected[..., 1]\n",
    "\n",
    "                _union_areas = _targets_areas + _outputs_areas - _intersect_areas\n",
    "\n",
    "                _IoU_scores = tf.expand_dims(_intersect_areas / tf.maximum(_union_areas, 1e-6), axis=-1)\n",
    "                _IoU_scores = tf.maximum(tf.minimum(_IoU_scores, 1), 0)\n",
    "\n",
    "                _bboxes_IoU = tf.reduce_mean(_IoU_scores)\n",
    "                bboxes_IoU.append(tf.cond(tf.is_finite(_bboxes_IoU), lambda: _bboxes_IoU, lambda: tf.constant(0, tf.float32)))\n",
    "\n",
    "                # Classes accuracy\n",
    "\n",
    "                if N_CLASSES > 0:\n",
    "                    _targets_classes_actual = tf.cast(tf.boolean_mask(_targets_classes, _detectors_mask), tf.int32)\n",
    "                    _outputs_classes_actual = tf.cast(tf.boolean_mask(outputs_classes, _detectors_mask), tf.int32)\n",
    "\n",
    "                    classes_accuracy.append(tf.reduce_mean(tf.cast(tf.equal(_targets_classes_actual, _outputs_classes_actual), tf.float32)))\n",
    "                    classes_confusion_matrix.append(tf.confusion_matrix(_targets_classes_actual, _outputs_classes_actual, num_classes=N_CLASSES))\n",
    "                    \n",
    "                    def _plot_confusion_matrix_wrapper(classes_confusion_matrix):\n",
    "                        return plot_confusion_matrix(classes_confusion_matrix, REGISTERED_CLASSES)\n",
    "\n",
    "                    _img = tf.py_func(_plot_confusion_matrix_wrapper, [classes_confusion_matrix[-1]], tf.uint8)\n",
    "                    classes_confusion_matrix_img.append(tf.expand_dims(_img, axis=0))\n",
    "\n",
    "        conf_probs_accuracy_mean = tf.reduce_mean(conf_probs_accuracy, axis=0)\n",
    "        conf_probs_precision_mean = tf.reduce_mean(conf_probs_precision, axis=0)\n",
    "        conf_probs_recall_mean = tf.reduce_mean(conf_probs_recall, axis=0)\n",
    "        conf_probs_f1_score_mean = tf.reduce_mean(conf_probs_f1_score, axis=0)\n",
    "        \n",
    "        bboxes_IoU_mean = tf.reduce_mean(bboxes_IoU, axis=0)\n",
    "        \n",
    "        if N_CLASSES > 0:\n",
    "            classes_accuracy_mean = tf.reduce_mean(classes_accuracy, axis=0)\n",
    "\n",
    "            classes_confusion_matrix_overal = tf.reduce_sum(classes_confusion_matrix, axis=0)\n",
    "\n",
    "            def _plot_confusion_matrix_wrapper(classes_confusion_matrix):\n",
    "                return plot_confusion_matrix(classes_confusion_matrix, REGISTERED_CLASSES)\n",
    "\n",
    "            classes_confusion_matrix_img_overal = tf.py_func(_plot_confusion_matrix_wrapper, [classes_confusion_matrix_overal], tf.uint8)\n",
    "            classes_confusion_matrix_img_overal = tf.expand_dims(classes_confusion_matrix_img_overal, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_summaries = []\n",
    "_summaries.append(tf.summary.scalar('loss/total', loss))\n",
    "_summaries.append(tf.summary.scalar('loss/conf-probs', conf_probs_loss))\n",
    "_summaries.append(tf.summary.scalar('loss/xy', xy_loss))\n",
    "_summaries.append(tf.summary.scalar('loss/wh', wh_loss))\n",
    "\n",
    "if N_CLASSES > 0:\n",
    "    _summaries.append(tf.summary.scalar('loss/classes', classes_loss))\n",
    "\n",
    "_summaries.append(tf.summary.scalar('learning-rate', lr_var))\n",
    "\n",
    "# _summaries.append(tf.summary.scalar('conf-probs-accuracy', conf_probs_accuracy))\n",
    "_summaries.append(tf.summary.scalar('conf-probs/precision', conf_probs_precision_mean))\n",
    "_summaries.append(tf.summary.scalar('conf-probs/recall', conf_probs_recall_mean))\n",
    "_summaries.append(tf.summary.scalar('conf-probs/f1-score', conf_probs_f1_score_mean))\n",
    "\n",
    "for output_grid, precision, recall, f1_score in zip(OUTPUT_GRIDS, conf_probs_precision, conf_probs_recall, conf_probs_f1_score):\n",
    "    _summaries.append(tf.summary.scalar('conf-probs/grid-%ix%i/precision' % tuple(output_grid), precision))\n",
    "    _summaries.append(tf.summary.scalar('conf-probs/grid-%ix%i/recall' % tuple(output_grid), recall))\n",
    "    _summaries.append(tf.summary.scalar('conf-probs/grid-%ix%i/f1-score' % tuple(output_grid), f1_score))\n",
    "\n",
    "_summaries.append(tf.summary.scalar('bboxes/IoU', bboxes_IoU_mean))\n",
    "\n",
    "for output_grid, iou in zip(OUTPUT_GRIDS, bboxes_IoU):\n",
    "    _summaries.append(tf.summary.scalar('bboxes/grid-%ix%i/IoU' % tuple(output_grid), iou))\n",
    "\n",
    "if N_CLASSES > 0:\n",
    "    _summaries.append(tf.summary.scalar('classes/accuracy', classes_accuracy_mean))\n",
    "    _summaries.append(tf.summary.image('classes/confusion-matrix', classes_confusion_matrix_img_overal))\n",
    "    for output_grid, accuracy, img in zip(OUTPUT_GRIDS, classes_accuracy, classes_confusion_matrix_img):\n",
    "        _summaries.append(tf.summary.scalar('classes/grid-%ix%i/accuracy' % tuple(output_grid), accuracy))\n",
    "        _summaries.append(tf.summary.image('classes/grid-%ix%i/confusion-matrix' % tuple(output_grid), img))\n",
    "\n",
    "for output_grid, _targets_nodes, _outputs_nodes in zip(OUTPUT_GRIDS, targets_nodes, output_nodes):\n",
    "    _targets_conf_probs = tf.cast(_targets_nodes[0], tf.float32)\n",
    "    _targets_conf_probs_bin = tf.cast(_targets_conf_probs >= CONFIDENCE_TRESH, tf.float32)\n",
    "    \n",
    "    _outputs_conf_probs = tf.cast(_outputs_nodes[0][1], tf.float32)\n",
    "    _outputs_conf_probs_bin = tf.cast(_outputs_conf_probs >= CONFIDENCE_TRESH, tf.float32)\n",
    "    \n",
    "    _summaries.append(tf.summary.image('conf-probs/grid-%ix%i/map' % tuple(output_grid), tf.cast(_outputs_conf_probs*255, tf.uint8)))\n",
    "    _summaries.append(tf.summary.image('conf-probs/grid-%ix%i/map-output' % tuple(output_grid), tf.cast(_outputs_conf_probs_bin*255, tf.uint8)))\n",
    "    _summaries.append(tf.summary.image('conf-probs/grid-%ix%i/map-target' % tuple(output_grid), tf.cast(_targets_conf_probs_bin*255, tf.uint8)))\n",
    "\n",
    "_summaries.append(tf.summary.image('images', inputs_image))\n",
    "\n",
    "train_summary_op = tf.summary.merge_all()\n",
    "valid_summary_op = tf.summary.merge(_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(TRAINING_DIR, 'model.ckpt')\n",
    "saver = tf.train.Saver(tf.global_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing parameters [OK]\n",
      "INFO:tensorflow:Restoring parameters from ./pretrained/resnet_v2_50/resnet_v2_50.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./training/resnet_v2_50/model.ckpt-75000\n",
      "Start trainging.\n",
      "Step #75500: train loss = 33.575405, valid loss = 47.858009, elapsed 890.270 sec.\n",
      "Step #76000: train loss = 38.721603, valid loss = 30.411934, elapsed 816.105 sec.\n",
      "Step #76500: train loss = 28.355383, valid loss = 57.116844, elapsed 956.569 sec.\n",
      "Step #77000: train loss = 17.806036, valid loss = 37.367558, elapsed 805.750 sec.\n",
      "Step #77500: train loss = 25.175249, valid loss = 31.464621, elapsed 799.229 sec.\n",
      "Step #78000: train loss = 27.120445, valid loss = 41.684307, elapsed 771.507 sec.\n",
      "Step #78500: train loss = 33.074959, valid loss = 48.926884, elapsed 829.357 sec.\n",
      "Step #79000: train loss = 30.642330, valid loss = 32.543900, elapsed 773.247 sec.\n",
      "Step #79500: train loss = 19.716675, valid loss = 36.876942, elapsed 731.665 sec.\n",
      "Step #80000: train loss = 36.518223, valid loss = 24.792019, elapsed 707.486 sec.\n",
      "Step #80500: train loss = 23.971035, valid loss = 34.393894, elapsed 823.108 sec.\n",
      "Step #81000: train loss = 29.094027, valid loss = 34.267590, elapsed 798.709 sec.\n",
      "Step #81500: train loss = 31.029079, valid loss = 56.962612, elapsed 861.300 sec.\n",
      "Step #82000: train loss = 36.836971, valid loss = 32.273300, elapsed 819.683 sec.\n",
      "Step #82500: train loss = 17.454233, valid loss = 42.506111, elapsed 676.793 sec.\n",
      "Step #83000: train loss = 28.731628, valid loss = 36.282795, elapsed 751.620 sec.\n",
      "Step #83500: train loss = 54.419132, valid loss = 40.263229, elapsed 729.661 sec.\n",
      "Step #84000: train loss = 25.088886, valid loss = 27.803879, elapsed 845.289 sec.\n",
      "Step #84500: train loss = 29.458975, valid loss = 35.931145, elapsed 736.553 sec.\n",
      "Step #85000: train loss = 38.440609, valid loss = 38.890575, elapsed 731.355 sec.\n",
      "Step #85500: train loss = 43.791466, valid loss = 42.581314, elapsed 809.913 sec.\n",
      "Step #86000: train loss = 22.212572, valid loss = 38.933567, elapsed 684.905 sec.\n",
      "Step #86500: train loss = 32.437321, valid loss = 30.855734, elapsed 670.418 sec.\n",
      "Step #87000: train loss = 24.584652, valid loss = 37.664604, elapsed 757.986 sec.\n",
      "Step #87500: train loss = 24.168489, valid loss = 51.374516, elapsed 676.774 sec.\n",
      "Step #88000: train loss = 27.650402, valid loss = 29.805925, elapsed 825.064 sec.\n",
      "Step #88500: train loss = 37.365097, valid loss = 33.436146, elapsed 874.994 sec.\n",
      "Step #89000: train loss = 28.996490, valid loss = 49.332184, elapsed 776.311 sec.\n",
      "Step #89500: train loss = 21.312811, valid loss = 41.264431, elapsed 833.467 sec.\n",
      "Step #90000: train loss = 19.524269, valid loss = 56.028458, elapsed 641.374 sec.\n",
      "Step #90500: train loss = 35.155766, valid loss = 23.814672, elapsed 749.323 sec.\n",
      "Step #91000: train loss = 32.254158, valid loss = 35.137493, elapsed 724.166 sec.\n",
      "Step #91500: train loss = 45.098793, valid loss = 47.726421, elapsed 953.883 sec.\n",
      "Step #92000: train loss = 22.570293, valid loss = 34.275314, elapsed 781.300 sec.\n",
      "Step #92500: train loss = 34.874157, valid loss = 35.997078, elapsed 708.814 sec.\n",
      "Step #93000: train loss = 36.248058, valid loss = 28.589245, elapsed 790.152 sec.\n",
      "Step #93500: train loss = 38.735661, valid loss = 58.927097, elapsed 826.122 sec.\n",
      "Step #94000: train loss = 25.105124, valid loss = 45.972008, elapsed 835.958 sec.\n",
      "Step #94500: train loss = 28.894041, valid loss = 25.668085, elapsed 788.729 sec.\n",
      "Step #95000: train loss = 29.948551, valid loss = 39.360657, elapsed 799.830 sec.\n",
      "Step #95500: train loss = 34.792984, valid loss = 38.142124, elapsed 842.348 sec.\n",
      "Step #96000: train loss = 26.730444, valid loss = 31.382963, elapsed 753.584 sec.\n",
      "Step #96500: train loss = 38.305882, valid loss = 31.648016, elapsed 793.727 sec.\n",
      "Step #97000: train loss = 30.981340, valid loss = 37.648521, elapsed 767.333 sec.\n",
      "Step #97500: train loss = 17.310886, valid loss = 41.727081, elapsed 802.425 sec.\n",
      "Step #98000: train loss = 27.417498, valid loss = 33.817062, elapsed 814.114 sec.\n",
      "Step #98500: train loss = 39.345722, valid loss = 20.235189, elapsed 741.586 sec.\n",
      "Step #99000: train loss = 28.522346, valid loss = 35.433674, elapsed 677.996 sec.\n",
      "Step #99500: train loss = 36.724926, valid loss = 44.416233, elapsed 801.330 sec.\n",
      "Step #100000: train loss = 40.707443, valid loss = 32.155552, elapsed 851.687 sec.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TRAINING_DIR):\n",
    "    os.makedirs(TRAINING_DIR)\n",
    "\n",
    "gpu_options = tf.GPUOptions(allow_growth=False, per_process_gpu_memory_fraction=GPU_MEMORY_FRACTION)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    try:\n",
    "        print('Initializing parameters ', flush=True, end='')\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        _train_ids, _train_entries = zip(*TRAIN_SAMPLES)\n",
    "        _valid_ids, _valid_entries = zip(*VALID_SAMPLES)\n",
    "        sess.run(train_iterator.initializer, {dataset_ids_tf_phr: _train_ids, dataset_samples_tf_phr: _train_entries})\n",
    "        sess.run(valid_iterator.initializer, {dataset_ids_tf_phr: _valid_ids, dataset_samples_tf_phr: _valid_entries})\n",
    "    \n",
    "        print('[OK]', flush=True)\n",
    "    except:\n",
    "        print('[Failed]', flush=True) \n",
    "        raise\n",
    "\n",
    "    if model_initial_weights_loader is not None:\n",
    "        model_initial_weights_loader(sess)\n",
    "            \n",
    "    ckpt = tf.train.get_checkpoint_state(TRAINING_DIR)\n",
    "    if ALLOW_RESTORING and ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        shutil.rmtree(TRAINING_DIR)\n",
    "        saver.save(sess, checkpoint_path)\n",
    "\n",
    "    with open(os.path.join(TRAINING_DIR, 'classes.json'), 'w') as f:\n",
    "        json.dump(REGISTERED_CLASSES, f)\n",
    "    tf.train.write_graph(sess.graph_def, TRAINING_DIR, 'graph.pb', as_text=False)\n",
    "    \n",
    "    _train_summary_writer = tf.summary.FileWriter(os.path.join(TRAINING_DIR, 'summary', 'train'), sess.graph)\n",
    "    _valid_summary_writer = tf.summary.FileWriter(os.path.join(TRAINING_DIR, 'summary', 'valid'), sess.graph)\n",
    "    \n",
    "    try:\n",
    "        _step = sess.run(step_var)\n",
    "        if _step == 0:\n",
    "            _train_loss, _train_summary = sess.run([loss, valid_summary_op], {data_loader_mode: 'train-pipe'})\n",
    "            _valid_loss, _valid_summary = sess.run([loss, valid_summary_op], {data_loader_mode: 'valid-pipe'})\n",
    "            _train_summary_writer.add_summary(_train_summary, _step)\n",
    "            _valid_summary_writer.add_summary(_valid_summary, _step)\n",
    "\n",
    "            print('Initial train loss = %.6f, valid loss = %.6f.' % (_train_loss, _valid_loss), flush=True)\n",
    "\n",
    "        print('Start trainging.', flush=True)\n",
    "        \n",
    "        start = time.time()\n",
    "        for _ in range(_step, TRAINING_STEPS):\n",
    "            sess.run(step_inc_op)\n",
    "            _step = sess.run(step_var)\n",
    "\n",
    "            sess.run([train_op], {is_training_mode: True,\n",
    "                                  data_loader_mode: 'train-pipe',\n",
    "                                  keep_prob: DROPOUT_KEEP_PROB})\n",
    "            \n",
    "            if _step % STEPS_PER_SUMMARY == 0:\n",
    "                _train_loss, _train_summary = sess.run([loss, train_summary_op], {data_loader_mode: 'train-pipe'})\n",
    "                _valid_loss, _valid_summary = sess.run([loss, valid_summary_op], {data_loader_mode: 'valid-pipe'})\n",
    "                _train_summary_writer.add_summary(_train_summary, _step)\n",
    "                _valid_summary_writer.add_summary(_valid_summary, _step)    \n",
    " \n",
    "                elapsed = time.time() - start\n",
    "                start = time.time()\n",
    "                print('Step #%i: train loss = %.6f, valid loss = %.6f, elapsed %.3f sec.' % (_step, _train_loss, _valid_loss, elapsed), flush=True)\n",
    "\n",
    "            if _step % STEPS_PER_CHECKPOINT == 0:\n",
    "                saver.save(sess, checkpoint_path, global_step=_step)\n",
    "\n",
    "        print('Training process is finished.', flush=True)\n",
    "    except Exception as ex:\n",
    "        last_error = ex\n",
    "        raise\n",
    "    finally:\n",
    "        saver.save(sess, checkpoint_path, global_step=_step)\n",
    "        tf.train.write_graph(sess.graph_def, TRAINING_DIR, 'graph.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
